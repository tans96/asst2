"""Convert NeRF transforms JSON files into renderer metadata format.

This script reads a NeRF-style transforms JSON file (as produced by the
original NeRF Blender dataset) and emits a metadata JSON that matches the
format generated by :mod:`scripts.datagen`. The resulting metadata can be fed
directly into the volumetric renderer training utilities.
"""

from __future__ import annotations

import argparse
import json
import math
import os
import shutil
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from PIL import Image
from tqdm import tqdm


SUPPORTED_IMAGE_EXTENSIONS: Tuple[str, ...] = (".png", ".jpg", ".jpeg", ".exr")


def _normalize_frame_path(frame_path: str) -> Path:
    """Strip the leading "./" that appears in NeRF frame file paths."""

    path = Path(frame_path)
    if path.is_absolute():
        return path

    text = str(path)
    if text.startswith("./"):
        text = text[2:]
    return Path(text)


def _resolve_image_path(frame_path: str, image_root: Path) -> Path:
    """Resolve the image path referenced by a NeRF frame description."""

    normalized = _normalize_frame_path(frame_path)
    candidate = (image_root / normalized).expanduser()

    if candidate.suffix:
        if candidate.exists():
            return candidate
    else:
        for ext in SUPPORTED_IMAGE_EXTENSIONS:
            trial = candidate.with_suffix(ext)
            if trial.exists():
                return trial

    raise FileNotFoundError(
        f"Could not resolve image for '{frame_path}' under {image_root}"
    )


def _matrix_to_quaternion(matrix: np.ndarray) -> Tuple[float, float, float, float]:
    """Convert a 3x3 rotation matrix into a (w, x, y, z) quaternion."""

    if matrix.shape != (3, 3):
        raise ValueError(f"Rotation matrix must be 3x3, received shape {matrix.shape}")

    m = matrix
    trace = float(m[0, 0] + m[1, 1] + m[2, 2])

    if trace > 0.0:
        s = math.sqrt(trace + 1.0) * 2.0
        w = 0.25 * s
        x = (m[2, 1] - m[1, 2]) / s
        y = (m[0, 2] - m[2, 0]) / s
        z = (m[1, 0] - m[0, 1]) / s
    elif m[0, 0] > m[1, 1] and m[0, 0] > m[2, 2]:
        s = math.sqrt(1.0 + m[0, 0] - m[1, 1] - m[2, 2]) * 2.0
        w = (m[2, 1] - m[1, 2]) / s
        x = 0.25 * s
        y = (m[0, 1] + m[1, 0]) / s
        z = (m[0, 2] + m[2, 0]) / s
    elif m[1, 1] > m[2, 2]:
        s = math.sqrt(1.0 + m[1, 1] - m[0, 0] - m[2, 2]) * 2.0
        w = (m[0, 2] - m[2, 0]) / s
        x = (m[0, 1] + m[1, 0]) / s
        y = 0.25 * s
        z = (m[1, 2] + m[2, 1]) / s
    else:
        s = math.sqrt(1.0 + m[2, 2] - m[0, 0] - m[1, 1]) * 2.0
        w = (m[1, 0] - m[0, 1]) / s
        x = (m[0, 2] + m[2, 0]) / s
        y = (m[1, 2] + m[2, 1]) / s
        z = 0.25 * s

    quat = np.array([w, x, y, z], dtype=np.float64)
    norm = np.linalg.norm(quat)
    if norm == 0.0:
        raise ValueError("Encountered zero-length quaternion while converting matrix")
    quat /= norm
    return tuple(float(component) for component in quat)


def _infer_vertical_fov(
    global_params: Dict[str, float],
    frame_params: Dict[str, float],
    width: int,
    height: int,
) -> float:
    """Infer the vertical field-of-view for a frame in degrees."""

    aspect = height / width

    if "camera_angle_y" in frame_params:
        return math.degrees(float(frame_params["camera_angle_y"]))
    if "camera_angle_y" in global_params:
        return math.degrees(float(global_params["camera_angle_y"]))

    if "fl_y" in frame_params:
        fl_y = float(frame_params["fl_y"])
        return math.degrees(2.0 * math.atan(height / (2.0 * fl_y)))
    if "fl_y" in global_params:
        fl_y = float(global_params["fl_y"])
        return math.degrees(2.0 * math.atan(height / (2.0 * fl_y)))

    if "camera_angle_x" in frame_params:
        fov_x = float(frame_params["camera_angle_x"])
    elif "camera_angle_x" in global_params:
        fov_x = float(global_params["camera_angle_x"])
    else:
        if "fl_x" in frame_params:
            fl_x = float(frame_params["fl_x"])
        elif "fl_x" in global_params:
            fl_x = float(global_params["fl_x"])
        else:
            raise ValueError(
                "Unable to infer field-of-view: missing camera_angle_{x,y} or focal lengths"
            )
        fov_x = 2.0 * math.atan(width / (2.0 * fl_x))

    return math.degrees(2.0 * math.atan(math.tan(fov_x / 2.0) * aspect))


def _get_image_size(path: Path) -> Tuple[int, int]:
    """Return the (width, height) of an image without loading pixel data."""

    with Image.open(path) as handle:
        return handle.size


def _prepare_image(
    source: Path,
    frame_path: str,
    output_dir: Path,
    mode: str,
) -> str:
    """Return the relative path to store in metadata, copying or linking as needed."""

    if mode not in {"reference", "copy", "symlink"}:
        raise ValueError(f"Unexpected image handling mode '{mode}'")

    if mode == "reference":
        relative = os.path.relpath(source, output_dir)
        return Path(relative).as_posix()

    relative_target = _normalize_frame_path(frame_path)
    relative_target = relative_target.with_suffix(source.suffix)
    destination = output_dir / relative_target
    destination.parent.mkdir(parents=True, exist_ok=True)

    if mode == "copy":
        shutil.copy2(source, destination)
    else:  # mode == "symlink"
        if destination.exists() or destination.is_symlink():
            destination.unlink()
        destination.symlink_to(source.resolve())

    return relative_target.as_posix()


def convert_nerf_dataset(
    transforms_path: Path,
    output_dir: Path,
    image_root: Path | None = None,
    metadata_filename: str = "metadata.json",
    image_mode: str = "reference",
) -> Path:
    """Convert a NeRF transforms JSON file into renderer metadata."""

    if image_mode not in {"reference", "copy", "symlink"}:
        raise ValueError(f"Unsupported image handling mode '{image_mode}'")

    with transforms_path.open("r", encoding="utf-8") as handle:
        payload: Dict[str, object] = json.load(handle)

    frames = list(payload.get("frames", []))  # type: ignore[arg-type]
    if not frames:
        raise ValueError(f"No frames found inside {transforms_path}")

    output_dir = output_dir.resolve()
    output_dir.mkdir(parents=True, exist_ok=True)
    image_root = (image_root or transforms_path.parent).resolve()

    first_image = _resolve_image_path(frames[0]["file_path"], image_root)
    width, height = _get_image_size(first_image)

    global_params = {k: v for k, v in payload.items() if k != "frames"}
    metadata_entries: List[Dict[str, object]] = []

    for frame in tqdm(frames, desc="Converting NeRF frames"):
        file_path = frame.get("file_path")
        if not isinstance(file_path, str):
            raise ValueError("Frame entry missing a valid 'file_path' string")

        transform_matrix = np.asarray(frame.get("transform_matrix"), dtype=np.float64)
        if transform_matrix.shape != (4, 4):
            raise ValueError("Each frame must contain a 4x4 'transform_matrix' array")

        rotation_matrix = transform_matrix[:3, :3]
        position = transform_matrix[:3, 3]
        quaternion = _matrix_to_quaternion(rotation_matrix)

        source_image = _resolve_image_path(file_path, image_root)
        frame_width = int(frame.get("w", width)) or width
        frame_height = int(frame.get("h", height)) or height
        vertical_fov = _infer_vertical_fov(
            global_params, frame, frame_width, frame_height
        )
        file_name = _prepare_image(source_image, file_path, output_dir, image_mode)

        metadata_entries.append(
            {
                "file_name": file_name,
                "position": position.astype(float).tolist(),
                "rotation": list(quaternion),
                "fov": float(vertical_fov),
            }
        )

    metadata = {"images": metadata_entries}
    metadata_path = output_dir / metadata_filename
    with metadata_path.open("w", encoding="utf-8") as handle:
        json.dump(metadata, handle, indent=2)

    return metadata_path


def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Convert NeRF transforms JSON to renderer metadata format"
    )
    parser.add_argument(
        "--transforms-path",
        type=Path,
        required=True,
        help="Path to the NeRF transforms_*.json file",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        required=True,
        help="Directory where metadata (and optionally images) will be written",
    )
    parser.add_argument(
        "--image-root",
        type=Path,
        default=None,
        help=(
            "Optional override for resolving frame file paths. Defaults to the"
            " transforms JSON parent directory."
        ),
    )
    parser.add_argument(
        "--metadata-name",
        type=str,
        default="metadata.json",
        help="Name of the metadata JSON file to emit",
    )
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument(
        "--copy-images",
        action="store_true",
        help="Copy images into the output directory",
    )
    mode_group.add_argument(
        "--symlink-images",
        action="store_true",
        help="Create symlinks into the output directory instead of copying",
    )
    return parser.parse_args()


def main() -> None:
    args = _parse_args()
    mode = "reference"
    if args.copy_images:
        mode = "copy"
    elif args.symlink_images:
        mode = "symlink"

    metadata_path = convert_nerf_dataset(
        transforms_path=args.transforms_path,
        output_dir=args.output_dir,
        image_root=args.image_root,
        metadata_filename=args.metadata_name,
        image_mode=mode,
    )

    print(f"Wrote metadata to {metadata_path}")


if __name__ == "__main__":
    main()
