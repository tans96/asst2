{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d36fb3",
   "metadata": {},
   "source": [
    "# Assignment 2 Part 1: Texture Mapping\n",
    "\n",
    "In this assignment, you are going to learn about wrapping a mesh with a texture map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f1cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[59173]: Class GLFWHelper is implemented in both /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x116a6d248) and /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x12660fa28). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[59173]: Class GLFWApplicationDelegate is implemented in both /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x116a6d298) and /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x12660fa78). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[59173]: Class GLFWWindowDelegate is implemented in both /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x116a6d2c0) and /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x12660faa0). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[59173]: Class GLFWContentView is implemented in both /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x116a6d310) and /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x12660faf0). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[59173]: Class GLFWWindow is implemented in both /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/slangpy/libsgl.dylib (0x116a6d388) and /Users/tejank10/cs248a-renderer-internal/.venv/lib/python3.12/site-packages/open3d/cpu/pybind.cpython-312-darwin.so (0x12660fb68). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n"
     ]
    }
   ],
   "source": [
    "import slangpy as spy\n",
    "from pyglm import glm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "from enum import Enum\n",
    "\n",
    "from cs248a_renderer import setup_device, RendererModules\n",
    "from cs248a_renderer.model.mesh import Mesh\n",
    "from cs248a_renderer.model.material import PhysicsBasedMaterial, MaterialField, FilteringMethod\n",
    "from cs248a_renderer.model.scene import Scene\n",
    "from cs248a_renderer.renderer.core_renderer import Renderer\n",
    "from cs248a_renderer.model.volumes import DenseVolume\n",
    "from cs248a_renderer.model.transforms import Transform3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2797cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36mINFO\u001b[0m] (\u001b[90mrhi\u001b[0m) layer: CreateDevice: Debug layer is enabled.\n",
      "[\u001b[33mWARN\u001b[0m] No supported shader model found, pretending to support sm_6_0.\n"
     ]
    }
   ],
   "source": [
    "# Device setup\n",
    "device = setup_device([])\n",
    "renderer_modules = RendererModules(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac6406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We setup the output image\n",
    "OUTPUT_IMG_SIZE = (512, 512)\n",
    "output_image = device.create_texture(\n",
    "    type=spy.TextureType.texture_2d,\n",
    "    format=spy.Format.rgba32_float,\n",
    "    usage=spy.TextureUsage.unordered_access,\n",
    "    width=OUTPUT_IMG_SIZE[0],\n",
    "    height=OUTPUT_IMG_SIZE[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cc6a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = Renderer(\n",
    "    device=device,\n",
    "    render_texture=output_image,\n",
    "    render_modules=renderer_modules\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60de315b",
   "metadata": {},
   "source": [
    "#### Download the requires meshes\n",
    "We are going to work with a simple triangle and plane meshes to drive home the point of texture mapping. Please download `triangle.obj` and `plane.obj` from the assignment 2 resources folder: [https://drive.google.com/drive/folders/1biYrBrNYx1sBlkcuyx3RARH9g9PaVHgL?usp=drive_link](https://drive.google.com/drive/folders/1biYrBrNYx1sBlkcuyx3RARH9g9PaVHgL?usp=drive_link)\n",
    "\n",
    "Place these files in the `resources` folder under the root directory of the repository (e.g., if your repository is located at `/path/to/cs248a-assignment2`, place the files in `/path/to/cs248a-assignment2/resources`). **Note:** This directory is ignored by `.gitignore`, so if you are working with your partner in group, make sure both of you have the files in your local `resources` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d281e",
   "metadata": {},
   "source": [
    "### Defining material for the surface\n",
    "So far, we've assumed that the surfaces that we are rendering are having a uniform color. Let's talk about it more formally now. A surface has a material. For eg. it could be a glossy surface (like plastic), metallic surface, diffused surface (most common, like wood, stone, found in everyday natural objects). In this noteobok we are going to assume that our surface has diffused material. We'll be rendering other kinds of materials in the upcoming assignments.\n",
    "\n",
    "Below, we begin with rendering a triangle in the same way that you did in the last assignment. While we do that, we are going to define the material in this triangle with a `PhysicsBasedMaterial`, whose properties are defined by `MaterialField`. We'll set its color to be while, which is defined in the `uniform_value`. This is the default color to be rendered in the absence of the albedo texture map, which has been the case so far in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48dd1c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SceneObject(name=root, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  SceneObject(name=object_1, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  ])\n",
       "])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll load a Triangle into our scene. This triangle is a right triangle of side length 100.\n",
    "scene = Scene()\n",
    "o3d_mesh = o3d.io.read_triangle_mesh(\"../../resources/triangle.obj\")\n",
    "mesh = Mesh(o3d_mesh)\n",
    "mesh.transform = Transform3D(\n",
    "    position=glm.vec3(0.0),\n",
    "\n",
    ")\n",
    "############## DEFINING A UNIFORM MATERIAL ###########\n",
    "mesh.material = PhysicsBasedMaterial(\n",
    "    albedo=MaterialField(\n",
    "        uniform_value=glm.vec3(1.0, 1.0, 1.0),\n",
    "        use_texture=False,\n",
    "        filtering_method=FilteringMethod.NEAREST,\n",
    "    ),\n",
    ")\n",
    "#######################################################\n",
    "\n",
    "scene.add_object(mesh)\n",
    "scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce45caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SceneObject(name=root, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  SceneObject(name=object_1, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  ])\n",
       "])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam = scene.camera\n",
    "eye = glm.vec3(50.0, 50.0, 200.0)\n",
    "lookAt = glm.vec3(50.0, 50.0, 0.0)\n",
    "\n",
    "cam.transform.position = eye\n",
    "cam.transform.rotation = glm.quatLookAt(glm.normalize(lookAt-eye), glm.vec3(0.0, 1.0, 0.0))\n",
    "scene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3f640d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "renderer.load_triangles(scene=scene)\n",
    "renderer.render(\n",
    "    scene.camera.view_matrix(),\n",
    "    scene.camera.fov\n",
    ")\n",
    "plt.imshow(np.flipud(output_image.to_numpy()))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f7981f",
   "metadata": {},
   "source": [
    "### UV Map\n",
    "Each mesh comes with vertices, and their corresponding UV coordinates. If you open any `.obj` file, the UV coordinates of a vertex are prefixed by `vt`. A `.obj` file first defines vertices followed by their corresponding UV coordinates, in the same order as vertices. These UV coordinates are used to sample the texture map to fetch albedo at vertex location.\n",
    "As you mgiht have guessed, we are not rendering just the vertices but the surface defined by them. Therefore, to color a surface we'd have to itnerpolate the UV coordinate at every hit point of ray-triangle intersection (which may not always be the vertex). To interpolate the UV coordinate at all locations on a triangle surface we take the help of Barycentric Coordinates.\n",
    "\n",
    "#### Barycentric Coordinates\n",
    "Barycentric Coordinates provide a method to interpolate between 3 points. The essence is very similar to the bilinear interpolation, which interpolates over a rectangle defined by 4 support points. Just like in bilinear interpolation, where the weights are defined by the ration area of the rectangles, the barycentric coordinates are defined by the ratio of the area of triangle subtended by the hitpoint to the edges.\n",
    "\n",
    "Implement `calculateBarycentricCoord` in the file `src/cs248a_renderer/slang_shaders/primitive/triangle.slang`. Then visualize the barycentric coordinates over the triangle that we just defined by setting the flag `visualize_barycentric_coords=True` in the `renderer.render`. This visualization shows the influence of each vertex on the surface. Red is highest influence of vertex 0 (bottom left), Green is for vertex 1 (bottom right) and Blue is for vertex 2 (top left).\n",
    "\n",
    "![Barycentric Coordinates](../../assets/bary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de3e52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "renderer.render(\n",
    "    scene.camera.view_matrix(),\n",
    "    scene.camera.fov,\n",
    "    visualize_barycentric_coords=True\n",
    ")\n",
    "plt.imshow(np.flipud(output_image.to_numpy()))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e8f883",
   "metadata": {},
   "source": [
    "### UV Coordinates\n",
    "Now we'll go ahead and interpolate the UV coordinates using the weights defined by the barycentric coordinates.\n",
    "\n",
    "Let's visualize the UV coordinates over the triangle by setting the flag `visualize_tex_uv=True` in the `renderer.render`.\n",
    "\n",
    "![Texture UV](../../assets/uv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f13b01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To visualize UV as RGB, we map UV to RG and fix B to 0.0.\n",
    "renderer.render(\n",
    "    scene.camera.view_matrix(),\n",
    "    scene.camera.fov,\n",
    "    visualize_tex_uv=True\n",
    ")\n",
    "plt.imshow(np.flipud(output_image.to_numpy()))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "043bfb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to get a meshed object\n",
    "class MaterialType(Enum):\n",
    "    UNIFORM = 'uniform'\n",
    "    ALBEDO_TEXTURE = 'albedo_texture'\n",
    "\n",
    "class ObjectType(Enum):\n",
    "    TRIANGLE = 'triangle'\n",
    "    PLANE = 'plane'\n",
    "\n",
    "def getObject(object_type=ObjectType.PLANE, material=MaterialType.UNIFORM, \\\n",
    "              filtering_method=FilteringMethod.NEAREST, \\\n",
    "              texture_map_path: str=None):\n",
    "    # We'll load a Plane into our scene, having side length 100.\n",
    "    if object_type == ObjectType.TRIANGLE:\n",
    "        o3d_mesh = o3d.io.read_triangle_mesh(\"../../resources/triangle.obj\")\n",
    "    elif object_type == ObjectType.PLANE:\n",
    "        o3d_mesh = o3d.io.read_triangle_mesh(\"../../resources/plane.obj\")\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid object type: {object_type}\")\n",
    "    mesh = Mesh(o3d_mesh)\n",
    "    mesh.transform = Transform3D(\n",
    "        position=glm.vec3(0.0),\n",
    "\n",
    "    )\n",
    "    if material == MaterialType.UNIFORM:\n",
    "        mesh.material = PhysicsBasedMaterial(\n",
    "            albedo=MaterialField(\n",
    "                uniform_value=glm.vec3(1.0, 1.0, 1.0),\n",
    "                use_texture=False,\n",
    "                filtering_method=filtering_method,\n",
    "            ),\n",
    "        )\n",
    "    elif material == MaterialType.ALBEDO_TEXTURE:\n",
    "        if texture_map_path is None:\n",
    "            raise ValueError(\"Texture map path is required for ALBEDO_TEXTURE material\")\n",
    "\n",
    "        mesh.material = PhysicsBasedMaterial(\n",
    "            albedo=MaterialField(\n",
    "                uniform_value=glm.vec3(1.0, 1.0, 1.0),\n",
    "                use_texture=True,\n",
    "                filtering_method=filtering_method,\n",
    "                texture_map_path=texture_map_path,\n",
    "            ),\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid material type: {material}\")\n",
    "    mesh.transform = Transform3D(\n",
    "        position=glm.vec3(0.0),\n",
    "    )\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7716f4",
   "metadata": {},
   "source": [
    "Let's look at the full UV map over a plane. Make sure you've downloaded the plane from [here](https://drive.google.com/file/d/1xaQgIj65Qc2nYXvqm8CC1wLVrDrGedRs/view?usp=drive_link) and placed it in the `resources` folder in the root directory of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b9c8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SceneObject(name=root, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  SceneObject(name=object_3, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  ])\n",
       "])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll load a Plane into our scene, having side length 100.\n",
    "scene = Scene()\n",
    "mesh = getObject(object_type=ObjectType.PLANE, material=MaterialType.UNIFORM)\n",
    "scene.add_object(mesh)\n",
    "cam = scene.camera\n",
    "eye = glm.vec3(50.0, 50.0, 200.0)\n",
    "lookAt = glm.vec3(50.0, 50.0, 0.0)\n",
    "\n",
    "cam.transform.position = eye\n",
    "cam.transform.rotation = glm.quatLookAt(glm.normalize(lookAt-eye), glm.vec3(0.0, 1.0, 0.0))\n",
    "scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0c309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To visualize UV as RGB, we map UV to RG and fix B to 0.0.\n",
    "renderer.load_triangles(scene=scene)\n",
    "renderer.render(\n",
    "    scene.camera.view_matrix(),\n",
    "    scene.camera.fov,\n",
    "    visualize_tex_uv=True\n",
    ")\n",
    "plt.imshow(np.flipud(output_image.to_numpy()))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230290c0",
   "metadata": {},
   "source": [
    "## Wrapping A Texture Onto The Plane\n",
    "After learning about how to get UV coordinates for any point on the surface, we are now ready to use it to wrap a texture on a surface. When we go to try that, we find two cases: a) what if the the texture map is too tiny compared to the surface? b) Or, what if it is too large?\n",
    "\n",
    "### Texture Magnification\n",
    "This happens when the area of texture map is much smaller than the area of mesh on which we want to wrap it. To demonstrate this, we are going to define a texture of size 2x2 containing 4 colors, RGBY. Then, we'll wrap it on the plane and render it, such that the plane occupies the whole image canvas of size 512x512.\n",
    "\n",
    "Since we are mapping a tiny texture map onto a large canvas, we need to think of a way to estimate the color for the pixels, where the UV coordinates do not map to a texel (pixel of texture map).\n",
    "\n",
    "#### Download Tiny Texture\n",
    "\n",
    "Download the `tiny_texture.png` from the assignment 2 resources folder: [https://drive.google.com/file/d/16vCrZx4ZKK9xaih-BV12COz4yEMZUnDH/view?usp=drive_link](https://drive.google.com/file/d/16vCrZx4ZKK9xaih-BV12COz4yEMZUnDH/view?usp=drive_link)\n",
    "\n",
    "Place it in the `resources` folder under the root directory of the repository (e.g., if your repository is located at `/path/to/cs248a-assignment2`, place the files in `/path/to/cs248a-assignment2/resources`). **Note:** This directory is ignored by `.gitignore`, so if you are working with your partner in group, make sure both of you have the files in your local `resources` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b95569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDi6KKK+ZP3EKKKKACiiigAooooA9Kooor5o/i8KKKKACiiigAooooA81ooor6U/tAKKKKACiiigAooooA9Kooor5o/i8KKKKACiiigAooooA81ooor6U/tAKKKKACiiigAooooA9Kooor5o/i8KKKKACiiigAooooA81ooor6U/tAKKKKACiiigAooooA9Kooor5o/i8KKKKACiiigAooooA8Gooor+vD9MCiiigAooooAKKKKAPsWiiiv4cPpgooooAKKKKACiiigD46ooor+4z5kKKKKACiiigAooooA+xaKKK/hw+mCiiigAooooAKKKKAPjqiiiv7jPmQooooAKKKKACiiigD7Fooor+HD6YKKKKACiiigAooooA+OqKKK/uM+ZCiiigAooooAKKKKAPsWiiiv4cPpgooooAKKKKACiiigD//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAACaklEQVR4AWL8zzC0wVD3ANPQDv6hD0YjYIDBaAQMMBiNgAEGoxEwwGA0AgYYjEbAAIPRCBhgMBoBAwxGI2CAwWgEDDAYjYABBqMRMMBgNAIGGIxGwACD0QgYYDAaAQMMRiNggMFoBAwwGI2AAQajETDAYDQCBhiMRsAAg9EIGGAwGgEDDEYjYIDBaAQMMBiNgAEGoxEwwGA0AgYYjEbAAIPRCBhgMBoBAwxGI2CAwWgEDDAYjYABBqMRMMBgNAIGGIxGwACD0QgYYDAaAQMMRiNggMFoBAwwGI2AAQajETDAYDQCBhiMRsAAg9EIGGAwGgEDDEYjYIDBaAQMMBiNgAEGoxEwwGA0AgYYjEbAAIPRCBhgMBoBAwxGI2CAwWgEDDAYjYABBqMRMMBgNAIGGIxGwAADRgaGoX2DwP//jAMchJRZP5oDBhiMRsAAg9EIGGAwGgEDDEYjYIDBaAQMMBiNgAEGoxEwwGA0AgYYjEbAAIPRCBhgMBoBAwxGI2CAwWgEDDAYjYABBqMRMMBgNAIGGIxGwACD0QgYYDAaAQMMRiNggMFoBAwwGI2AAQajETDAYDQCBhiMRsAAg9EIGGAwGgEDDEYjYIDBaAQMMBiNgAEGoxEwwGA0AgYYjEbAAIPRCBhgMBoBAwxGI2CAwWgEDDAYjYABBqMRMMBgNAIGGIxGwACD0QgYYDAaAQMMRiNggMFoBAwwGI2AAQajETDAYDQCBhiMRsAAg9EIGGAwGgEDDEYjYIDBaAQMMBiNgAEGoxEwwGA0AgYYjEbAAIPRCBhgMBoBAwxGI2CAwWgEDDAYjQDABjgCAMPnBfzyHS9YAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TINY_TEXTURE_IMAGE_PATH = \"../../resources/tiny_texture.png\"\n",
    "tiny_texture_img = Image.open(TINY_TEXTURE_IMAGE_PATH)\n",
    "# Visualize the tiny texture, resize it to 128x128 for visualization purposees\n",
    "tiny_texture_img.resize((128, 128), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6aaf6",
   "metadata": {},
   "source": [
    "#### Nearest Sampling\n",
    "In this method, we set the color of the pixel to the texel at the nearest UV coordinate to it's corresponding one.\n",
    "Implement `pointSample` function of `struct SharedTexture2DBuffer` in file `src/cs248a_renderer/slang_shaders/texture/texture.slang`. Upon a successful implementation, rendering a plane with this texture onto a 512x512 sized canvas should get the following blocky output:\n",
    "\n",
    "![nearest](../../assets/nearest.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb139ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SceneObject(name=root, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  SceneObject(name=object_5, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  ])\n",
       "])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene = Scene()\n",
    "mesh = getObject(object_type=ObjectType.PLANE,\\\n",
    "                material=MaterialType.ALBEDO_TEXTURE,\\\n",
    "                filtering_method=FilteringMethod.NEAREST,\\\n",
    "                texture_map_path=TINY_TEXTURE_IMAGE_PATH)\n",
    "scene.add_object(mesh)\n",
    "\n",
    "# Move the camera such that the 100x100 plane is fully occupying \n",
    "# the 512x512 canvas upon rendering.\n",
    "cam = scene.camera\n",
    "eye = glm.vec3(50.0, 50.0, 120.5)\n",
    "lookAt = glm.vec3(50.0, 50.0, 0.0)\n",
    "\n",
    "cam.transform.position = eye\n",
    "cam.transform.rotation = glm.quatLookAt(glm.normalize(lookAt-eye), glm.vec3(0.0, 1.0, 0.0))\n",
    "scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "686e6d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To visualize UV as RGB, we map UV to RG and fix B to 0.0.\n",
    "renderer.load_triangles(scene=scene)\n",
    "renderer.render(\n",
    "    scene.camera.view_matrix(),\n",
    "    scene.camera.fov,\n",
    ")\n",
    "plt.imshow(np.flipud(output_image.to_numpy()))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094af415",
   "metadata": {},
   "source": [
    "#### Bilinear Sampling\n",
    "Bilinear sampling gets rid of the blocky effect that we just saw, we set the color of the pixel to the interpolated color from the texel surrounding it's corresponding UV.\n",
    "\n",
    "Implement the `bilinearSample` function of `struct SharedTexture2DBuffer` in file `src/cs248a_renderer/slang_shaders/texture/texture.slang`. Upon a successful implementation, rendering a plane with this texture onto a 512x512 sized canvas should get the following smooth output:  \n",
    "\n",
    "![bilinear](../../assets/bilinear.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6938b248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SceneObject(name=root, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  SceneObject(name=object_7, transform=Transform3D(position=vec3( 0, 0, 0 ), rotation=quat( 1, 0, 0, 0 ), scale=vec3( 1, 1, 1 )), children=[\n",
       "  ])\n",
       "])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene = Scene()\n",
    "mesh = getObject(object_type=ObjectType.PLANE,\\\n",
    "                material=MaterialType.ALBEDO_TEXTURE,\\\n",
    "                filtering_method=FilteringMethod.BILINEAR,\\\n",
    "                texture_map_path=TINY_TEXTURE_IMAGE_PATH)\n",
    "scene.add_object(mesh)\n",
    "cam = scene.camera\n",
    "eye = glm.vec3(50.0, 50.0, 120.5)\n",
    "lookAt = glm.vec3(50.0, 50.0, 0.0)\n",
    "\n",
    "cam.transform.position = eye\n",
    "cam.transform.rotation = glm.quatLookAt(glm.normalize(lookAt-eye), glm.vec3(0.0, 1.0, 0.0))\n",
    "scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62ab4fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To visualize UV as RGB, we map UV to RG and fix B to 0.0.\n",
    "renderer.load_triangles(scene=scene)\n",
    "renderer.render(\n",
    "    scene.camera.view_matrix(),\n",
    "    scene.camera.fov,\n",
    ")\n",
    "plt.imshow(np.flipud(output_image.to_numpy()))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c19e7",
   "metadata": {},
   "source": [
    "### Texture Minification\n",
    "We just saw the phenomenon of texture magnification, where texture map's area is too small to fill in the whole canvas. Let's now look at what happens when texture map's area is too large.\n",
    "\n",
    "In this section, we are going to render image of plane such that it's parallel to the ground. When a plane is rendered such that it's parallel to the ground, the points near the horizon need to sample over large space on the texture map, giving rise to texture minification in these regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81dc7b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(511.5), np.float64(511.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########### LOAD PLANE WITH UNIFORM COLOR ###########\n",
    "\n",
    "scene = Scene()\n",
    "mesh = getObject(object_type=ObjectType.PLANE,\\\n",
    "                 material=MaterialType.UNIFORM,\\\n",
    "                 filtering_method=FilteringMethod.NEAREST)\n",
    "scene.add_object(mesh)\n",
    "\n",
    "########### SET CAMERA SUCH THAT PLANE IS ON GROUND ###########\n",
    "\n",
    "cam = scene.camera\n",
    "eye = glm.vec3(50.0, -50.0, 25.0)\n",
    "lookAt = glm.vec3(50.0, 100.0, 0.0)\n",
    "\n",
    "cam.transform.position = eye\n",
    "cam.transform.rotation = glm.quatLookAt(glm.normalize(lookAt-eye), glm.vec3(0.0, 1.0, 0.0))\n",
    "\n",
    "########### RENDER ###########\n",
    "\n",
    "renderer.load_triangles(scene=scene)\n",
    "renderer.render(\n",
    "    scene.camera.view_matrix(),\n",
    "    scene.camera.fov,\n",
    ")\n",
    "plt.imshow(np.flipud(output_image.to_numpy()))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba4392",
   "metadata": {},
   "source": [
    "#### Download the Texture Map\n",
    "Download the `fabric.png` from the assignment 2 resources folder: [https://drive.google.com/file/d/1b7Kb9xMul02BalnZp5vNvb7-K98NdyNx/view?usp=drive_link](https://drive.google.com/file/d/1b7Kb9xMul02BalnZp5vNvb7-K98NdyNx/view?usp=drive_link)\n",
    "\n",
    "Place it in the `resources` folder under the root directory of the repository (e.g.\n",
    "\n",
    "#### Creation of Mipmaps\n",
    "Let's prepare for the texture minification by creating a hierarchy of mipmaps. We are going to use `fabric.png` which is a texture map of a fabric at 512x512 resolution. At this point, recall that the output image is also declared to be of the same size. \n",
    "\n",
    "A mipmap is a texture map that's prefiltered using low-pass filtering. Level 0 mipmap is unfilted texture map. Higher level mipmaps are low-filtered (downsampled) with more strength, which reduces their size. Level i mipmap is 2^i times smaller than the original one!\n",
    "\n",
    "Here we show the different levels of the mipmap of the texture that you're going to overlay onto the plane.\n",
    "\n",
    "![mipmaps](../../assets/mipmaps.png)\n",
    "\n",
    "To get this result, let's implement the function `generate_mipmaps` in `src/cs248a_renderer/model/material.py`. This function takes level 0 texture image as input generates the mipmap hierarchy from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c04fa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ALBEDO_TEXTURE_IMAGE_PATH = \"../../resources/fabric.png\"\n",
    "material = MaterialField(\n",
    "    uniform_value=glm.vec3(1.0, 1.0, 1.0),\n",
    "    use_texture=True,\n",
    "    filtering_method=FilteringMethod.NEAREST,\n",
    "    texture_map_path=ALBEDO_TEXTURE_IMAGE_PATH,\n",
    ")\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(2):\n",
    "    for j in range(len(material.textures) // 2):\n",
    "        plt.subplot(2, 4, i * len(material.textures) // 2 + j + 1)\n",
    "        plt.imshow(material.textures[i * 4 + j])\n",
    "        plt.title(f\"Level {i * 4 + j}\", fontsize=18)\n",
    "        plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b0db85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to render the plane with different filtering methods\n",
    "def renderPlane(filtering_method: FilteringMethod, \\\n",
    "                visualize_albedo: bool=True, \\\n",
    "                visualize_level_of_detail: bool=False, \\\n",
    "                texture_map_path: str=ALBEDO_TEXTURE_IMAGE_PATH\n",
    "    ):\n",
    "    scene = Scene()\n",
    "    mesh = getObject(object_type=ObjectType.PLANE,\\\n",
    "                    material=MaterialType.ALBEDO_TEXTURE,\\\n",
    "                    filtering_method=filtering_method,\\\n",
    "                    texture_map_path=texture_map_path)\n",
    "    scene.add_object(mesh)\n",
    "\n",
    "    cam = scene.camera\n",
    "    eye = glm.vec3(50.0, -50.0, 25.0)\n",
    "    lookAt = glm.vec3(50.0, 100.0, 0.0)\n",
    "\n",
    "    cam.transform.position = eye\n",
    "    cam.transform.rotation = glm.quatLookAt(glm.normalize(lookAt-eye), glm.vec3(0.0, 1.0, 0.0))\n",
    "\n",
    "    renderer.load_triangles(scene=scene)\n",
    "\n",
    "    if visualize_albedo and visualize_level_of_detail:\n",
    "        raise ValueError(\"Cannot visualize both albedo and level of detail in the same render call. Choose one!\")\n",
    "\n",
    "    renderer.render(\n",
    "        scene.camera.view_matrix(),\n",
    "        scene.camera.fov,\n",
    "        visualize_albedo=visualize_albedo,\n",
    "        visualize_level_of_detail=visualize_level_of_detail\n",
    "    )\n",
    "    return np.flipud(output_image.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d672c",
   "metadata": {},
   "source": [
    "#### Aliasing at horizon\n",
    "If we use the interpolation methods implemented so far to render plane with this texture, we see aliasing effect at the horizon.\n",
    "\n",
    "<div style=\"display: flex; gap: 10px;\">\n",
    "\n",
    "  <figure style=\"width: 50%; margin: 0; text-align: center;\">\n",
    "    <img src=\"../../assets/aliasing_nearest.png\" style=\"width: 100%;\" />\n",
    "    <figcaption style=\"margin-top: 5px; font-weight: bold;\">Nearest</figcaption>\n",
    "  </figure>\n",
    "\n",
    "  <figure style=\"width: 50%; margin: 0; text-align: center;\">\n",
    "    <img src=\"../../assets/aliasing_bilinear.png\" style=\"width: 100%;\" />\n",
    "    <figcaption style=\"margin-top: 5px; font-weight: bold;\">Bilinear</figcaption>\n",
    "  </figure>\n",
    "\n",
    "</div>\n",
    "\n",
    "<!-- ![aliasing_nearest](../../assets/aliasing_nearest.png) ![aliasing_bilinear](../../assets/aliasing_bilinear.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bfa6f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_image_np = renderPlane(FilteringMethod.NEAREST, \n",
    "                           visualize_albedo=True, \n",
    "                           visualize_level_of_detail=False,\n",
    "                           texture_map_path=ALBEDO_TEXTURE_IMAGE_PATH)\n",
    "plt.imshow(output_image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fe2b72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_image_np = renderPlane(FilteringMethod.BILINEAR, \n",
    "                           visualize_albedo=True, \n",
    "                           visualize_level_of_detail=False,\n",
    "                           texture_map_path=ALBEDO_TEXTURE_IMAGE_PATH)\n",
    "plt.imshow(output_image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33808109",
   "metadata": {},
   "source": [
    "#### Why are we observing aliasing in this example?\n",
    "Farther a point is from the camera, lower will be the texture resolution at that point. But previous interpolation method do not take resolution into account while samplint a texel. For eg. the line at the horizon in this rendering is supposed to be from a lower mipmap level. But previous interpolation methods simply sample from level 0 mipmap without low-pass filtering which culminates in aliasing.\n",
    "\n",
    "Below image demonstrates the levels of the plane (darker blue is lower level). Observe how the level increase as we move closer to the horizon.  \n",
    "\n",
    "![bilinear_levels](../../assets/levels_bilinear.png)\n",
    "\n",
    "Now let's minimize aliasing by using mipmaps. First, we'll get mipmap level at each hit point. To do this, implement the function `getLevel` in `src/cs248a_renderer/slang_shaders/renderer/triangle_renderer.slang` using ray differentials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12140571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_image_np = renderPlane(FilteringMethod.BILINEAR_DISCRETIZED_LEVEL, \n",
    "                           visualize_albedo=False, \n",
    "                           visualize_level_of_detail=True,\n",
    "                           texture_map_path=ALBEDO_TEXTURE_IMAGE_PATH)\n",
    "plt.imshow(output_image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f9079a",
   "metadata": {},
   "source": [
    "Let's visualize the texture rendered with bilinear discretized level, which chooses approapriate mipmap according to the level to bilinearly sample the texel. It should produce an output as follows (note the smoothing at the horizon)\n",
    "\n",
    "![bdl](../../assets/bdl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16720ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_image_np = renderPlane(FilteringMethod.BILINEAR_DISCRETIZED_LEVEL, \n",
    "                           visualize_albedo=True, \n",
    "                           visualize_level_of_detail=False,\n",
    "                           texture_map_path=ALBEDO_TEXTURE_IMAGE_PATH)\n",
    "plt.imshow(output_image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984dddd6",
   "metadata": {},
   "source": [
    "#### Trilinear Filtering\n",
    "While Bilinear filtering with discretized levels solves the problem of aliasing, it stumbles upon a new problem of discretization in levels. Specifically, observe a shift in the smoothness of the texture at the middle the image where the level is _suddenly_ increasing.\n",
    "\n",
    "To smoothen this shift, we again resort to the ancient technique of interpolation. The only step trilinear filtering adds over the previous bilinear with discretized levels is interpolation in level space.\n",
    "\n",
    "To do this, go ahead and implement the function `trilinearSample` in `src/cs248a_renderer/slang_shaders/texture/texture.slang`. Levels from a successful implementation should look like the following (note the smoothened levels as we look towards the horizon)  \n",
    "\n",
    "![trilinear_levels](../../assets/trilineat_levels.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c51b46d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_image_np = renderPlane(FilteringMethod.TRILINEAR, \n",
    "                           visualize_albedo=False, \n",
    "                           visualize_level_of_detail=True,\n",
    "                           texture_map_path=ALBEDO_TEXTURE_IMAGE_PATH)\n",
    "plt.imshow(output_image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e547b0",
   "metadata": {},
   "source": [
    "Finally, let's look at the trilinearly filtered image of the textured plane. Note a smooth gradation in the texture as we look towards the horizon.\n",
    "\n",
    "![trilinear](../../assets/trilinear_filt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a5fcf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPdJREFUeJzt2yEOQ0EIQEG2+fe/MlV9el3bZEYjcC8Izu7uAMDMvL69AAC/QxQAiCgAEFEAIKIAQEQBgIgCABEFAPLMpXPO7SgAP+jmV9mlAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAnrm0u7ejAPwplwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPPxBhlxDQeZ6EaEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_image_np = renderPlane(FilteringMethod.TRILINEAR, \n",
    "                           visualize_albedo=True, \n",
    "                           visualize_level_of_detail=False,\n",
    "                           texture_map_path=ALBEDO_TEXTURE_IMAGE_PATH)\n",
    "plt.imshow(output_image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
